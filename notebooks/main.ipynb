{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 3.11.5\n",
    "\n",
    "**Library versions:**\n",
    "\n",
    "* matplotlib==3.8.0\n",
    "\n",
    "* numpy==1.26.0\n",
    "\n",
    "* pandas==2.1.1\n",
    "\n",
    "* scikit-learn==1.3.1\n",
    " \n",
    "* seaborn==0.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully yay!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "\n",
    "\n",
    "print(\"Libraries imported successfully yay!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Dataset Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/diabetes_binary_health_indicators_BRFSS2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Basic Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Transform the data to integer values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age']=df['Age'].astype('int64')\n",
    "df['Education']=df['Education'].astype('int64')\n",
    "df['Income']=df['Income'].astype('int64')\n",
    "df['BMI']=df['BMI'].astype('int64')\n",
    "df['CholCheck']=df['CholCheck'].astype('int64')\n",
    "df['Smoker']=df['Smoker'].astype('int64')\n",
    "df['Stroke']=df['Stroke'].astype('int64')\n",
    "df['HeartDiseaseorAttack']=df['HeartDiseaseorAttack'].astype('int64')\n",
    "df['PhysActivity']=df['PhysActivity'].astype('int64')\n",
    "df['Fruits']=df['Fruits'].astype('int64')\n",
    "df['Veggies']=df['Veggies'].astype('int64')\n",
    "df['HvyAlcoholConsump']=df['HvyAlcoholConsump'].astype('int64')\n",
    "df['AnyHealthcare']=df['AnyHealthcare'].astype('int64')\n",
    "df['NoDocbcCost']=df['NoDocbcCost'].astype('int64')\n",
    "df['GenHlth']=df['GenHlth'].astype('int64')\n",
    "df['MentHlth']=df['MentHlth'].astype('int64')\n",
    "df['PhysHlth']=df['PhysHlth'].astype('int64')\n",
    "df['DiffWalk']=df['DiffWalk'].astype('int64')\n",
    "df['Sex']=df['Sex'].astype('int64')\n",
    "df['Diabetes_binary']=df['Diabetes_binary'].astype('int64')\n",
    "df['HighBP']=df['HighBP'].astype('int64')\n",
    "df['HighChol']=df['HighChol'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Check for missing data (null values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Check for duplicated data and remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"There are: {duplicates} duplicates\")\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Get dataset information on rows x columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 Check number of unique values in different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    unique_values[col] = df[col].value_counts().shape[0]\n",
    "\n",
    "pd.DataFrame(unique_values, index=['# Unique Values']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.6 Rename target variable name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Diabetes_binary': 'Diabetes'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Stacked Bar Chart Analysis of Features vs. Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', \n",
    "               'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', \n",
    "               'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_pivot(data, column):\n",
    "    return data.groupby([column, 'Diabetes']).size().unstack(fill_value=0)\n",
    "\n",
    "def plot_stacked_bars(data, columns):\n",
    "    _, axes = plt.subplots(3, 4, figsize=(15, 15))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i, col in enumerate(columns):\n",
    "        if i >= len(axes):\n",
    "            break\n",
    "        create_pivot(data, col).plot(kind='bar', stacked=True, ax=axes[i])\n",
    "        axes[i].set_title(col)\n",
    "        axes[i].set_xlabel(col)\n",
    "\n",
    "    # Turn off unused subplots\n",
    "    for ax in axes[len(columns):]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_stacked_bars(df, binary_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Target Distribution across the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Diabetes', data=df)\n",
    "plt.title('Diabetes Prevalence')\n",
    "plt.xlabel('Diabetes (0: No Diabetes, 1: Has Diabetes)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "for bar in plt.gca().containers:\n",
    "    plt.gca().bar_label(bar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of people with diabetes and people with no diabetes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_counts = df['Diabetes'].value_counts()\n",
    "\n",
    "# Plot the pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    diabetes_counts, \n",
    "    labels=['No Diabetes (0)', 'Has Diabetes (1)'], \n",
    "    autopct='%.02f%%',\n",
    "    startangle=90, \n",
    ")\n",
    "plt.title('Diabetes Prevalence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more people without diabetes than people with diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Diabetes Prevalence by Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.copy()\n",
    "df_plot['Sex'] = df_plot['Sex'].replace({1: 'Male', 0: 'Female'})\n",
    "\n",
    "sns.barplot(x='Sex', y='Diabetes', data=df_plot, errorbar=None)\n",
    "plt.title('Diabetes Risk by Gender')\n",
    "plt.ylabel('Proportion with Diabetes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Diabetes Prevalence by Age Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age Categories Mapping\n",
    "age_category_map = {\n",
    "    1: '18-24', \n",
    "    2: '25-29', \n",
    "    3: '30-34', \n",
    "    4: '35-39', \n",
    "    5: '40-44',\n",
    "    6: '45-49', \n",
    "    7: '50-54', \n",
    "    8: '55-59', \n",
    "    9: '60-64', \n",
    "    10: '65-69', \n",
    "    11: '70-74', \n",
    "    12: '75-79', \n",
    "    13: '80+'\n",
    "}\n",
    "\n",
    "# Countplot \n",
    "plt.figure(figsize=(20, 6))\n",
    "sns.countplot(x='Age', hue='Diabetes', data=df, order=range(1, 14))\n",
    "plt.title('Diabetes Prevalence by Age')\n",
    "plt.xlabel('Age Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Consider only people with diabetes (Diabetes = 1)\n",
    "df_diabetes = df[df['Diabetes'] == 1]\n",
    "\n",
    "# Calculate the total count per age category\n",
    "age_category_count_diabetes = df_diabetes['Age'].value_counts().sort_index()\n",
    "\n",
    "# Find the age category with the highest count for people with diabetes\n",
    "max_age_category_diabetes = age_category_count_diabetes.idxmax()\n",
    "max_count_diabetes = age_category_count_diabetes.max()\n",
    "\n",
    "max_age_group_diabetes = age_category_map[max_age_category_diabetes]\n",
    "\n",
    "print(f\"Age category with the highest number of people with diabetes: {max_age_category_diabetes} ({max_age_group_diabetes} years old) with a total of {max_count_diabetes} people.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As age increases so does the diabetes diagnostic in people. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 Diabetes Prevalence in Males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for males with diabetes\n",
    "df_males = df[(df['Sex'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot \n",
    "sns.countplot(x='Age', hue='Diabetes', data=df_males, order=range(1, 14))\n",
    "plt.title('Diabetes Prevalence in Males by Age Category')\n",
    "plt.xlabel('Age Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "df_males_diabetes = df_males[df_males['Diabetes'] == 1]\n",
    "\n",
    "age_category_count_male_diabetes = df_males_diabetes['Age'].value_counts().sort_index()\n",
    "\n",
    "max_age_category_male_diabetes = age_category_count_male_diabetes.idxmax()\n",
    "max_count_male_diabetes = age_category_count_male_diabetes.max()\n",
    "\n",
    "max_age_group_male_diabetes = age_category_map[max_age_category_male_diabetes]\n",
    "\n",
    "print(f\"Age category with the highest number of people with diabetes: {max_age_category_male_diabetes} ({max_age_group_male_diabetes} years old) with a total of {max_count_male_diabetes} people.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_males_bmi_above_40 = df[(df['Sex'] == 1) & (df['BMI'] > 40)]\n",
    "\n",
    "# Calculate the count of males with diabetes (Diabetes == 1) and without diabetes (Diabetes == 0)\n",
    "diabetes_count = df_males_bmi_above_40['Diabetes'].value_counts()\n",
    "\n",
    "# Calculate the percentage of males with BMI > 40 who have diabetes\n",
    "diabetes_percentage = (diabetes_count.get(1, 0) / len(df_males_bmi_above_40)) * 100\n",
    "no_diabetes_percentage = 100 - diabetes_percentage\n",
    "\n",
    "# Create a pie chart (circle plot)\n",
    "labels = ['With Diabetes', 'Without Diabetes']\n",
    "sizes = [diabetes_percentage, no_diabetes_percentage]\n",
    "colors = ['#ff9999','#66b3ff']\n",
    "explode = (0.1, 0)  \n",
    "\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Percentage of Diabetic Males with BMI > 40')\n",
    "plt.axis('equal')  \n",
    "plt.show()\n",
    "\n",
    "print(f\"Percentage diabetic males with BMI > 40: {diabetes_percentage:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 Diabetes Prevalence in Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats for females with diabetes\n",
    "df_females = df[(df['Sex'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot \n",
    "sns.countplot(x='Age', hue='Diabetes', data=df_females, order=range(1, 14))\n",
    "plt.title('Diabetes Prevalence in Females by Age Category')\n",
    "plt.xlabel('Age Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "df_females_diabetes = df_females[df_females['Diabetes'] == 1]\n",
    "\n",
    "age_category_count_female_diabetes = df_females_diabetes['Age'].value_counts().sort_index()\n",
    "\n",
    "max_age_category_female_diabetes = age_category_count_female_diabetes.idxmax()\n",
    "max_count_female_diabetes = age_category_count_female_diabetes.max()\n",
    "\n",
    "max_age_group_female_diabetes = age_category_map[max_age_category_female_diabetes]\n",
    "\n",
    "print(f\"Age category with the highest number of people with diabetes: {max_age_category_female_diabetes} ({max_age_group_female_diabetes} years old) with a total of {max_count_female_diabetes} people.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_females_bmi_above_40 = df[(df['Sex'] == 0) & (df['BMI'] > 40)]\n",
    "\n",
    "# Calculate the count of females with diabetes (Diabetes == 1) and without diabetes (Diabetes == 0)\n",
    "diabetes_count = df_females_bmi_above_40['Diabetes'].value_counts()\n",
    "\n",
    "# Calculate the percentage of females with BMI > 40 who have diabetes\n",
    "diabetes_percentage = (diabetes_count.get(1, 0) / len(df_females_bmi_above_40)) * 100\n",
    "no_diabetes_percentage = 100 - diabetes_percentage\n",
    "\n",
    "# Create a pie chart (circle plot)\n",
    "labels = ['With Diabetes', 'Without Diabetes']\n",
    "sizes = [diabetes_percentage, no_diabetes_percentage]\n",
    "colors = ['#ff9999','#66b3ff']\n",
    "explode = (0.1, 0)  \n",
    "\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Percentage of Diabetic Females with BMI > 40')\n",
    "plt.axis('equal')  \n",
    "plt.show()\n",
    "\n",
    "print(f\"Percentage diabetic females with BMI > 40: {diabetes_percentage:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.7 Diabetes and Risk Factors Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI Analysis\n",
    "sns.boxplot(x='Diabetes', y='BMI', data=df)\n",
    "plt.title('BMI Distribution by Diabetes Risk')\n",
    "plt.xlabel('Diabetes (0: No Diabetes, 1: Has Diabetes)')\n",
    "plt.ylabel('BMI')\n",
    "plt.show()\n",
    "\n",
    "# Impact of Physical Activity and Diabetes\n",
    "sns.barplot(x='PhysActivity', y='Diabetes', data=df, errorbar=None)\n",
    "plt.title('Diabetes Risk by Physical Activity')\n",
    "plt.xlabel('Physical Activity (1: Yes, 0: No)')\n",
    "plt.ylabel('Proportion with Diabetes')\n",
    "plt.show()\n",
    "\n",
    "# Impact of Smoking and Diabetes \n",
    "sns.barplot(x='Smoker', y='Diabetes', data=df, errorbar=None)\n",
    "plt.title('Diabetes Risk by Smoking Status')\n",
    "plt.xlabel('Smoking (1: Yes, 0: No)')\n",
    "plt.ylabel('Proportion with Diabetes')\n",
    "plt.show()\n",
    "\n",
    "# Impact of General Health Status and Diabetes\n",
    "sns.barplot(x='GenHlth', y='Diabetes', data=df, errorbar=None)\n",
    "plt.title('Diabetes Risk by General Health')\n",
    "plt.xlabel('General Health (1: Excellent, 5: Poor)')\n",
    "plt.ylabel('Proportion with Diabetes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.8 Education Feature vs. Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Histogram for No Diabetic group\n",
    "sns.histplot(df.Education[df.Diabetes == 0], color=\"y\", label=\"No Diabetes\", kde=True, stat=\"density\")\n",
    "\n",
    "# Histogram for Diabetic group\n",
    "sns.histplot(df.Education[df.Diabetes == 1], color=\"m\", label=\"Has Diabetes\", kde=True, stat=\"density\")\n",
    "\n",
    "plt.title(\"Relation b/w Education and Diabetes\")\n",
    "plt.xlabel(\"Education\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "- There are more people with higher levels of education.\n",
    "- There are more people without diabetes who have higher levels of education."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Correlation of Features with Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Diabetes', axis=1).corrwith(df.Diabetes).plot(kind='bar', grid=True, figsize=(16, 4), title=\"Correlation with Diabetes\",color=\"Brown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### High Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr = df.corr()\n",
    "high_corr_features = high_corr.index[abs((high_corr[\"Diabetes\"])) >= 0.1]\n",
    "high_corr_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Low Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_corr = df.corr()\n",
    "low_corr_features = low_corr.index[abs(low_corr[\"Diabetes\"]) < 0.05]\n",
    "low_corr_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping low correlated features\n",
    "\n",
    "low_corr = ['Smoker', 'Fruits', 'Veggies', 'AnyHealthcare', 'NoDocbcCost', 'Sex']\n",
    "df.drop(low_corr , axis= 1 ,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Data Splitting for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Target Variable\n",
    "X = df.drop('Diabetes', axis = 1)\n",
    "y = df['Diabetes']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Support Vector Machine\": SVC(kernel='linear'),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(), \n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Get accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results.append((name, accuracy))\n",
    "\n",
    "    # Metrics\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix for {name}:\\n{cm}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=['Negative', 'Positive'], \n",
    "                yticklabels=['Negative', 'Positive'])\n",
    "    plt.title(f\"Confusion Matrix for {name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df_results = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\"])\n",
    "df_results = df_results.sort_values(by=\"Accuracy\", ascending=False)\n",
    "\n",
    "# Print sorted results\n",
    "print(\"Summary of Results:\")\n",
    "# print(df_results.to_string(index=False))\n",
    "\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "def hyperparameter_tuning(model, param_dist, X_train, y_train, X_test, y_test, cv=5, n_candidates=50, scoring='accuracy'):\n",
    "    halving_random_search = HalvingRandomSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_dist,\n",
    "        n_candidates=n_candidates,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        verbose=2,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "    )\n",
    "    halving_random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Extract the best model and parameters\n",
    "    best_model = halving_random_search.best_estimator_\n",
    "    best_params = halving_random_search.best_params_\n",
    "\n",
    "    print(f\"Best Model Parameters: {best_params}\")\n",
    "    print(f\"Best {model.__class__.__name__} Score: {halving_random_search.best_score_:.4f}\")\n",
    "    print(f\"Best {model.__class__.__name__} Estimator: {best_model}\")\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        \"recall\": recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        \"classification_report\": classification_report(y_test, y_pred),\n",
    "        \"confusion_matrix\": cm\n",
    "    }\n",
    "\n",
    "    # Display metrics\n",
    "    print(\"\\nEvaluation Metrics on Test Set:\")\n",
    "    for metric, value in metrics.items():\n",
    "        if metric == \"confusion_matrix\":\n",
    "            print(f\"\\n{metric}:\\n{value}\")\n",
    "        elif metric == \"classification_report\":\n",
    "            print(f\"\\n{metric}:\\n{value}\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    # Confusion Matrix Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # Save the model name, accuracy, and other relevant metrics\n",
    "    result = {\n",
    "        \"model\": model.__class__.__name__,\n",
    "        \"best_accuracy\": halving_random_search.best_score_,\n",
    "        \"test_accuracy\": metrics[\"accuracy\"],\n",
    "        \"params\": best_params\n",
    "    }\n",
    "    results.append(result)\n",
    "    \n",
    "    return best_model, best_params, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "param_dist = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  \n",
    "    'solver': ['liblinear', 'saga', 'lbfgs'],  \n",
    "    'max_iter': [100, 200, 300],  \n",
    "    'penalty': ['l1', 'l2'],  \n",
    "}\n",
    "\n",
    "best_model, best_params, metrics = hyperparameter_tuning(\n",
    "    model=model,\n",
    "    param_dist=param_dist,\n",
    "    X_train=X_train,  \n",
    "    y_train=y_train,  \n",
    "    X_test=X_test,    \n",
    "    y_test=y_test,   \n",
    "    cv=5,             \n",
    "    n_candidates=20,        \n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250],\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "}\n",
    "\n",
    "best_model, best_params, metrics = hyperparameter_tuning(\n",
    "    model=model,\n",
    "    param_dist=param_dist,\n",
    "    X_train=X_train,  \n",
    "    y_train=y_train,  \n",
    "    X_test=X_test,    \n",
    "    y_test=y_test,   \n",
    "    cv=5,             \n",
    "    n_candidates=20,        \n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "}\n",
    "\n",
    "best_model, best_params, metrics = hyperparameter_tuning(\n",
    "    model=model,\n",
    "    param_dist=param_dist,\n",
    "    X_train=X_train,  \n",
    "    y_train=y_train,  \n",
    "    X_test=X_test,    \n",
    "    y_test=y_test,   \n",
    "    cv=5,             \n",
    "    n_candidates=20,        \n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 KNeighborsClassifier Model (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "\n",
    "param_dist = {\n",
    "    'n_neighbors': [3, 5, 7, 10],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1, 2],  \n",
    "    'leaf_size': [20, 30, 40, 50],  \n",
    "}\n",
    "\n",
    "best_model, best_params, metrics = hyperparameter_tuning(\n",
    "    model=model,\n",
    "    param_dist=param_dist,\n",
    "    X_train=X_train,  \n",
    "    y_train=y_train,  \n",
    "    X_test=X_test,    \n",
    "    y_test=y_test,   \n",
    "    cv=5,             \n",
    "    n_candidates=20,        \n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "\n",
    "param_dist = {\n",
    "    'C': [0.1, 1, 10, 100],  \n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  \n",
    "    'degree': [3, 4, 5],  \n",
    "    'gamma': ['scale', 'auto'],  \n",
    "}\n",
    "\n",
    "best_model, best_params, metrics = hyperparameter_tuning(\n",
    "    model=model,\n",
    "    param_dist=param_dist,\n",
    "    X_train=X_train,  \n",
    "    y_train=y_train,  \n",
    "    X_test=X_test,    \n",
    "    y_test=y_test,   \n",
    "    cv=5,             \n",
    "    n_candidates=20,        \n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'warm_start': [True, False],\n",
    "    'n_iter_no_change': [5, 10, 20],\n",
    "}\n",
    "\n",
    "best_model, best_params, metrics = hyperparameter_tuning(\n",
    "    model=model,\n",
    "    param_dist=param_dist,\n",
    "    X_train=X_train,  \n",
    "    y_train=y_train,  \n",
    "    X_test=X_test,    \n",
    "    y_test=y_test,   \n",
    "    cv=5,             \n",
    "    n_candidates=20,        \n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for results in order of best test accuracy\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"test_accuracy\", ascending=False)\n",
    "\n",
    "print(\"\\nModel Comparison (Sorted by Test Accuracy):\")\n",
    "print(results_df[[\"model\", \"test_accuracy\", \"best_accuracy\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
